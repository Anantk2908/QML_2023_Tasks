{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JQi86HXFNL5k"
   },
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LafSwQELP8EG"
   },
   "outputs": [],
   "source": [
    "!pip -q install cirq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-16T12:04:47.553024Z",
     "start_time": "2023-03-16T12:04:45.729126Z"
    },
    "id": "vxcMjMsQNL5l"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cirq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SDVE2ZNnNL5m"
   },
   "source": [
    "* Using Cirq for Quantum Operations\n",
    "    1) With 5 qubits \n",
    "    2) Apply Hadamard operation on every qubit \n",
    "    3) Apply CNOT operation on (0, 1), (1,2), (2,3), (3,4) \n",
    "    4) SWAP (0, 4) \n",
    "    5) Rotate X with pi/2 on any qubit \n",
    "    6) Plot the circuit \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-16T12:04:49.394961Z",
     "start_time": "2023-03-16T12:04:49.384967Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z4fJ2fUearpo",
    "outputId": "7cf76e40-b0dc-42f9-845c-d23079fc610a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: ───H───@───────────────×───Rx(0.5π)───\n",
      "          │               │\n",
      "2: ───H───X───@───────────┼──────────────\n",
      "              │           │\n",
      "3: ───H───────X───@───────┼──────────────\n",
      "                  │       │\n",
      "4: ───H───────────X───@───┼──────────────\n",
      "                      │   │\n",
      "5: ───H───────────────X───×──────────────\n"
     ]
    }
   ],
   "source": [
    "# Making 5 named Qubits\n",
    "import cirq\n",
    "a = cirq.NamedQubit('1')\n",
    "b = cirq.NamedQubit('2')\n",
    "c = cirq.NamedQubit('3')\n",
    "d = cirq.NamedQubit('4')\n",
    "e = cirq.NamedQubit('5')\n",
    "\n",
    "# Performing the necessary operations\n",
    "operations = [cirq.H(a), cirq.H(b),cirq.H(c),cirq.H(d),cirq.H(e), cirq.CNOT(a, b),cirq.CNOT(b, c),cirq.CNOT(c, d),cirq.CNOT(d,e),cirq.SWAP(a,e),cirq.Rx(rads = 0.5 * np.pi)(a)]\n",
    "\n",
    "#Plotting the Cirquit\n",
    "print(cirq.Circuit(operations))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ywmZ6z4VNL5n"
   },
   "source": [
    "* Implement a second circuit with a framework of your choice:\n",
    "\n",
    "1.   Apply a Hadmard gate to the first qubit\n",
    "2.   rotate the second qubit by pi/3 around X\n",
    "3.   Apply Hadamard gate to the third and fourth qubit\n",
    "4.   Perform a swap test between the states of the first and second qubit |q1 q2> and the third and fourth qubit |q3 q4> \n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iyxP4P_mPhne",
    "outputId": "fa5f853f-1d2f-4475-a4c4-aefe7aba1bfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 529, 1: 471})\n"
     ]
    }
   ],
   "source": [
    "import cirq\n",
    "import numpy as np\n",
    "\n",
    "# Create a quantum circuit with 4 qubits\n",
    "qc = cirq.Circuit()\n",
    "q = cirq.LineQubit.range(4)\n",
    "\n",
    "# Apply Hadamard gate to the first qubit\n",
    "qc.append(cirq.H(q[0]))\n",
    "\n",
    "# Rotate the second qubit by pi/3 around X\n",
    "qc.append(cirq.rx(np.pi/3).on(q[1]))\n",
    "\n",
    "# Apply Hadamard gate to the third and fourth qubit\n",
    "qc.append(cirq.H(q[2]))\n",
    "qc.append(cirq.H(q[3]))\n",
    "\n",
    "# Perform a swap test between the states of the first and second qubit |q1 q2> \n",
    "# and the third and fourth qubit |q3 q4>\n",
    "\n",
    "# Initialize an ancilla qubit\n",
    "anc = cirq.NamedQubit('anc')\n",
    "qc.append(cirq.H(anc))\n",
    "\n",
    "# Apply controlled swap gates\n",
    "qc.append(cirq.CSWAP(q[0], q[1], anc))\n",
    "qc.append(cirq.CSWAP(q[2], q[3], anc))\n",
    "\n",
    "# Apply controlled-Hadamard gates\n",
    "qc.append(cirq.H(q[0]).controlled_by(anc))\n",
    "qc.append(cirq.H(q[1]).controlled_by(anc))\n",
    "qc.append(cirq.H(q[2]).controlled_by(anc))\n",
    "qc.append(cirq.H(q[3]).controlled_by(anc))\n",
    "\n",
    "# Measure the ancilla qubit\n",
    "qc.append(cirq.measure(anc, key='result'))\n",
    "\n",
    "# Simulate the circuit and print the results\n",
    "simulator = cirq.Simulator()\n",
    "result = simulator.run(qc, repetitions=1000)\n",
    "print(result.histogram(key='result'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gb8I4QF8UoiW"
   },
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TqtPhvPxUqJ7",
    "outputId": "73ed013e-7183-45af-8ee1-32cb766f4276"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m700.5/700.5 KB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m502.3/502.3 KB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m616.2/616.2 KB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install -q energyflow\n",
    "!pip install -q torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "K6EoOa7N8T33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the GCN model\n",
      "Epoch: 1, Train Loss: 0.6766\n",
      "Epoch: 2, Train Loss: 0.6347\n",
      "Epoch: 3, Train Loss: 0.6058\n",
      "Epoch: 4, Train Loss: 0.5898\n",
      "Epoch: 5, Train Loss: 0.5636\n",
      "Epoch: 6, Train Loss: 0.5569\n",
      "Epoch: 7, Train Loss: 0.5629\n",
      "Epoch: 8, Train Loss: 0.5487\n",
      "Epoch: 9, Train Loss: 0.5351\n",
      "Epoch: 10, Train Loss: 0.5585\n",
      "Epoch: 11, Train Loss: 0.5307\n",
      "Epoch: 12, Train Loss: 0.5492\n",
      "Epoch: 13, Train Loss: 0.5419\n",
      "Epoch: 14, Train Loss: 0.5329\n",
      "Epoch: 15, Train Loss: 0.5268\n",
      "Epoch: 16, Train Loss: 0.5378\n",
      "Epoch: 17, Train Loss: 0.5341\n",
      "Epoch: 18, Train Loss: 0.5413\n",
      "Epoch: 19, Train Loss: 0.5291\n",
      "Epoch: 20, Train Loss: 0.5590\n",
      "Epoch: 21, Train Loss: 0.5327\n",
      "Epoch: 22, Train Loss: 0.5309\n",
      "Epoch: 23, Train Loss: 0.5260\n",
      "Epoch: 24, Train Loss: 0.5380\n",
      "Epoch: 25, Train Loss: 0.5333\n",
      "Training GAT model\n",
      "Epoch: 1, Train Loss: 0.7333\n",
      "Epoch: 2, Train Loss: 0.5595\n",
      "Epoch: 3, Train Loss: 0.6021\n",
      "Epoch: 4, Train Loss: 0.5585\n",
      "Epoch: 5, Train Loss: 0.5359\n",
      "Epoch: 6, Train Loss: 0.5613\n",
      "Epoch: 7, Train Loss: 0.5577\n",
      "Epoch: 8, Train Loss: 0.5415\n",
      "Epoch: 9, Train Loss: 0.5519\n",
      "Epoch: 10, Train Loss: 0.5755\n",
      "Epoch: 11, Train Loss: 0.5387\n",
      "Epoch: 12, Train Loss: 0.5398\n",
      "Epoch: 13, Train Loss: 0.5412\n",
      "Epoch: 14, Train Loss: 0.5373\n",
      "Epoch: 15, Train Loss: 0.5483\n",
      "Epoch: 16, Train Loss: 0.5350\n",
      "Epoch: 17, Train Loss: 0.5401\n",
      "Epoch: 18, Train Loss: 0.5430\n",
      "Epoch: 19, Train Loss: 0.5357\n",
      "Epoch: 20, Train Loss: 0.5275\n",
      "Epoch: 21, Train Loss: 0.5401\n",
      "Epoch: 22, Train Loss: 0.5342\n",
      "Epoch: 23, Train Loss: 0.5369\n",
      "Epoch: 24, Train Loss: 0.5372\n",
      "Epoch: 25, Train Loss: 0.5443\n",
      "Performance Metrics for the GCN model\n",
      "GCN AUC-ROC: 0.8883\n",
      "GCN Confusion Matrix:\n",
      "[[101  46]\n",
      " [ 19 134]]\n",
      "GCN Accuracy: 0.7833\n",
      "Performance Metrics for the GAT model\n",
      "GAT AUC-ROC: 0.8799\n",
      "GAT Confusion Matrix:\n",
      "[[ 94  53]\n",
      " [ 14 139]]\n",
      "GAT Accuracy: 0.7767\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GATConv\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import to_undirected\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import energyflow as ef\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "num_data = 1000\n",
    "X, y = ef.qg_jets.load(num_data=num_data, pad=True, ncol=4)\n",
    "\n",
    "# Preprocess the dataset\n",
    "def create_graph(jet):\n",
    "    # Here we create a simple graph using only the pt, rapidity, and azimuthal angle columns\n",
    "    positions = jet[:, 1:3]\n",
    "    features = torch.tensor(jet[:, :3], dtype=torch.float)\n",
    "\n",
    "    # Calculate distances between all pairs of nodes (particles) and threshold to create edges\n",
    "    dist_threshold = 0.3\n",
    "    distance_matrix = np.linalg.norm(positions[:, np.newaxis] - positions, axis=2)\n",
    "    edges = np.argwhere(distance_matrix < dist_threshold)\n",
    "\n",
    "    # Remove self-loops\n",
    "    edges = edges[edges[:, 0] != edges[:, 1]]\n",
    "\n",
    "    undirected_edges = to_undirected(torch.tensor(edges, dtype=torch.long).t().contiguous())\n",
    "    return Data(x=features, edge_index=undirected_edges)\n",
    "\n",
    "\n",
    "graph_dataset = [create_graph(jet) for jet in X]\n",
    "train_indices, test_indices = train_test_split(range(len(graph_dataset)), test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "# Define GCN model\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_features, hidden_channels, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Define GAT model\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, num_features, hidden_channels, num_classes, num_heads=4):\n",
    "        super(GAT, self).__init__()\n",
    "        self.conv1 = GATConv(num_features, hidden_channels, heads=num_heads)\n",
    "        self.conv2 = GATConv(hidden_channels * num_heads, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Training function\n",
    "def train(model, dataset, train_indices, epochs=25, batch_size=16, device='cpu'):\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        train_loss = 0.0\n",
    "        np.random.shuffle(train_indices)\n",
    "        model.train()\n",
    "        for i in range(0, len(train_indices), batch_size):\n",
    "            batch_indices = train_indices[i: i + batch_size]\n",
    "            batch = [dataset[idx] for idx in batch_indices]\n",
    "            batch_labels = torch.tensor([y[idx] for idx in batch_indices], dtype=torch.long, device=device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            batch_logits = torch.stack([model(graph.to(device)).mean(dim=0) for graph in batch], dim=0)\n",
    "            loss = loss_fn(batch_logits, batch_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        train_loss /= len(train_indices) / batch_size\n",
    "        print(f\"Epoch: {epoch + 1}, Train Loss: {train_loss:.4f}\")\n",
    "\n",
    "#Calculating Accuracy\n",
    "def accuracy(y_true, y_pred):\n",
    "    assert len(y_true) == len(y_pred), \"The lengths of true and predicted labels must match.\"\n",
    "    correct = np.sum(y_true == y_pred)\n",
    "    return correct / len(y_true)\n",
    "\n",
    "\n",
    "def evaluate(model, dataset, test_indices, device='cpu'):\n",
    "    model.eval()\n",
    "    logits, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for idx in test_indices:\n",
    "            graph = dataset[idx].to(device)\n",
    "            label = y[idx]\n",
    "            logit = model(graph).mean(dim=0)\n",
    "            logits.append(logit.cpu().numpy())\n",
    "            labels.append(label)\n",
    "\n",
    "    logits = np.stack(logits)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    pred_probs = np.exp(logits)[:, 1]\n",
    "    auc_roc = roc_auc_score(labels, pred_probs)\n",
    "    pred_labels = np.argmax(logits, axis=1)\n",
    "    cm = confusion_matrix(labels, pred_labels)\n",
    "    acc = accuracy(labels, pred_labels)\n",
    "\n",
    "    return auc_roc, cm, acc\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_features = 3\n",
    "hidden_channels = 64\n",
    "num_classes = 2\n",
    "\n",
    "# Initialize and train GCN model\n",
    "gcn_model = GCN(num_features, hidden_channels, num_classes).to(device)\n",
    "print(\"Training the GCN model\")\n",
    "train(gcn_model, graph_dataset, train_indices, device=device)\n",
    "\n",
    "\n",
    "# Initialize and train GAT model\n",
    "gat_model = GAT(num_features, hidden_channels, num_classes).to(device)\n",
    "print(\"Training GAT model\")\n",
    "train(gat_model, graph_dataset, train_indices, device=device)\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate GCN model\n",
    "gcn_auc_roc, gcn_cm, gcn_acc = evaluate(gcn_model, graph_dataset, test_indices, device=device)\n",
    "print(\"Performance Metrics for the GCN model\")\n",
    "print(f\"GCN AUC-ROC: {gcn_auc_roc:.4f}\")\n",
    "print(f\"GCN Confusion Matrix:\\n{gcn_cm}\")\n",
    "print(f\"GCN Accuracy: {gcn_acc:.4f}\")\n",
    "\n",
    "# Evaluate GAT model\n",
    "gat_auc_roc, gat_cm, gat_acc = evaluate(gat_model, graph_dataset, test_indices, device=device)\n",
    "print(\"Performance Metrics for the GAT model\")\n",
    "print(f\"GAT AUC-ROC: {gat_auc_roc:.4f}\")\n",
    "print(f\"GAT Confusion Matrix:\\n{gat_cm}\")\n",
    "print(f\"GAT Accuracy: {gat_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GCN model has an AUC-ROC score of 0.8883 and an accuracy of 0.7833, while the GAT model has an AUC-ROC score of 0.8799 and an accuracy of 0.7767.\n",
    "\n",
    "The confusion matrix shows that the GCN model correctly predicted 101 + 134 = 235 events, while the GAT model correctly predicted 94 + 139 = 233 events. Both models misclassified 46 and 53 events, respectively.\n",
    "\n",
    "It should be noted that the performance of the models can be improved by using hyperparameter tuning, adjusting the number of layers and the size of the hidden layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8OKUVpPt-ujk"
   },
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YtyQ_gd6-xAW"
   },
   "source": [
    "Quantum computing has always piqued my curiosity since I first encountered Shor's algorithm, a revolutionary method for factoring large numbers exponentially faster than classical algorithms. As a budding computer science engineer, I am eager to explore and contribute to this disruptive technology that holds immense potential.\n",
    "\n",
    "My initial exposure to quantum computing involved using TensorFlow Quantum and Cirq libraries, which provided a solid foundation in understanding the intricacies of quantum systems. Currently, I am delving into the Pennylane library, which has opened up new avenues for me to explore the fascinating world of quantum machine learning.\n",
    "\n",
    "I believe that quantum machine learning offers unprecedented opportunities to solve complex problems that were previously deemed unsolvable. One particular method I would love to work on is the development of hybrid quantum-classical algorithms, which can leverage the best of both worlds to deliver optimized solutions in areas such as optimization and pattern recognition.\n",
    "\n",
    "As I continue to expand my knowledge in quantum computing, I am excited to uncover the untapped potential of this groundbreaking technology and make significant contributions to its advancement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GgLU0cloky62"
   },
   "source": [
    "# Task 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "auvWkBNNkyc7"
   },
   "source": [
    "A Quantum Graph Neural Network(QGNN) is the quantum analogue of the classical graph neural networks. The are designed such as to use quantum phenomenon such as superposition to their advantage and process the graph structured data more efficiently.\n",
    "\n",
    "An approach for creating QGNN for classifying quarks and gluons using the graph representation is as follows:\n",
    "\n",
    "1) Embedding the input graph into a quantum state: We can use single-qubit gates such as RY ot RZ gates to encode the data.\n",
    "\n",
    "2) Apply a parameterized quantum circuit: In this step we can capture the graph's structure through entangling gates such as CNOT gates. We choose the entangling gate based on the adjancency matrix of the graphical gata.\n",
    "\n",
    "3) Measure the output quantum state: After applying the quantum operations, we can measure the output quantum state to obtain classical information. For example, you can use expectation values of observables to extract the output node or graph-level features.\n",
    "\n",
    "4) Decode the output features and perform a classical post-processing step: This step involves using a classical neural network or other machine learning algorithms to make the final predictions for quark and gluon classification based on the output features from the QGNN circuit.\n",
    "\n",
    "5) Train the QGNN circuit using a hybrid quantum-classical optimization approach: We can optimize the parameters of the quantum circuit using gradient-based optimization techniques, such as gradient descent or Adam. The gradients can be computed using classical backpropagation or using quantum parameter-shift rules.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given below is simple implementation of a QGNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "aWjYhH5ZQgfX"
   },
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.templates import RandomLayers\n",
    "\n",
    "def quantum_graph_embedding(A, X, params, n_qubits):\n",
    "    for i in range(n_qubits):\n",
    "        qml.RY(np.pi * X[i], wires=i)\n",
    "    \n",
    "    for j in range(n_qubits):\n",
    "        for k in range(j+1, n_qubits):\n",
    "            if A[j][k] == 1:\n",
    "                qml.CNOT(wires=[j, k])\n",
    "                qml.RY(params[j][k], wires=k)\n",
    "                qml.CNOT(wires=[j, k])\n",
    "\n",
    "def qgnn_circuit(A, X, params, n_qubits, n_layers):\n",
    "    wires = list(range(n_qubits))\n",
    "    dev = qml.device(\"default.qubit\", wires=wires)\n",
    "\n",
    "    @qml.qnode(dev)\n",
    "    def circuit(params):\n",
    "        for layer in range(n_layers):\n",
    "            quantum_graph_embedding(A, X, params[layer], n_qubits)\n",
    "            RandomLayers(params[layer], wires=wires)\n",
    "\n",
    "        return qml.probs(wires=wires)\n",
    "\n",
    "    return circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: ──RY(1.57)─╭●───────────╭●─────────────────╭RandomLayers(M0)──RY(1.57)─╭●───────────╭●───\n",
      "1: ──RY(0.94)─╰X──RY(4.49)─╰X─╭●───────────╭●─├RandomLayers(M0)──RY(0.94)─╰X──RY(4.97)─╰X─╭●\n",
      "2: ──RY(2.51)─────────────────╰X──RY(4.06)─╰X─╰RandomLayers(M0)──RY(2.51)─────────────────╰X\n",
      "\n",
      "───────────────╭RandomLayers(M1)──RY(1.57)─╭●───────────╭●─────────────────╭RandomLayers(M2)─┤ ╭Probs\n",
      "────────────╭●─├RandomLayers(M1)──RY(0.94)─╰X──RY(5.47)─╰X─╭●───────────╭●─├RandomLayers(M2)─┤ ├Probs\n",
      "───RY(0.45)─╰X─╰RandomLayers(M1)──RY(2.51)─────────────────╰X──RY(4.90)─╰X─╰RandomLayers(M2)─┤ ╰Probs\n"
     ]
    }
   ],
   "source": [
    "# Create a sample adjacency matrix (A) and node feature matrix (X) for demonstration purposes\n",
    "A = np.array([[0, 1, 0], [1, 0, 1], [0, 1, 0]])\n",
    "X = np.array([0.5, 0.3, 0.8])\n",
    "\n",
    "# Number of qubits and layers in the QGNN circuit\n",
    "n_qubits = len(A)\n",
    "n_layers = 3\n",
    "\n",
    "# Randomly initialize the parameters\n",
    "params = np.random.uniform(0, 2 * np.pi, (n_layers, n_qubits, n_qubits))\n",
    "\n",
    "# Get the circuit drawing\n",
    "qgnn_circuit_instance = qgnn_circuit(A, X, params, n_qubits, n_layers)\n",
    "qgnn_circuit_instance(params)\n",
    "print(qml.draw(qgnn_circuit_instance)(params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some corner cases that may occur in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Empty Graph\n",
    "An event with only one particle detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: ──RY(0.00)──RandomLayers(M0)──RY(0.00)──RandomLayers(M1)──RY(0.00)──RandomLayers(M2)─┤  Probs\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[0]])\n",
    "X = np.array([0.0])\n",
    "n_qubits = len(A)\n",
    "n_layers = 3\n",
    "\n",
    "params = np.random.uniform(0, 2 * np.pi, (n_layers, n_qubits, n_qubits))\n",
    "\n",
    "qgnn_circuit_instance = qgnn_circuit(A, X, params, n_qubits, n_layers)\n",
    "qgnn_circuit_instance(params)\n",
    "print(qml.draw(qgnn_circuit_instance)(params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Graph\n",
    "A situation where particles interact sequentially, with each particle primarily interacting with its neighbors in the chain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: ──RY(0.31)─╭●───────────╭●─────────────────╭RandomLayers(M0)──RY(0.31)─╭●───────────╭●───\n",
      "1: ──RY(0.63)─╰X──RY(4.86)─╰X─╭●───────────╭●─├RandomLayers(M0)──RY(0.63)─╰X──RY(2.26)─╰X─╭●\n",
      "2: ──RY(0.94)─────────────────╰X──RY(3.88)─╰X─╰RandomLayers(M0)──RY(0.94)─────────────────╰X\n",
      "\n",
      "───────────────╭RandomLayers(M1)──RY(0.31)─╭●───────────╭●─────────────────╭RandomLayers(M2)─┤ ╭Probs\n",
      "────────────╭●─├RandomLayers(M1)──RY(0.63)─╰X──RY(2.29)─╰X─╭●───────────╭●─├RandomLayers(M2)─┤ ├Probs\n",
      "───RY(4.19)─╰X─╰RandomLayers(M1)──RY(0.94)─────────────────╰X──RY(0.64)─╰X─╰RandomLayers(M2)─┤ ╰Probs\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[0, 1, 0], [1, 0, 1], [0, 1, 0]])\n",
    "X = np.array([0.1, 0.2, 0.3])\n",
    "\n",
    "n_qubits = len(A)\n",
    "n_layers = 3\n",
    "\n",
    "params = np.random.uniform(0, 2 * np.pi, (n_layers, n_qubits, n_qubits))\n",
    "\n",
    "qgnn_circuit_instance = qgnn_circuit(A, X, params, n_qubits, n_layers)\n",
    "qgnn_circuit_instance(params)\n",
    "print(qml.draw(qgnn_circuit_instance)(params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xa2YNDgdCHLU"
   },
   "source": [
    "# Task 8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 683,
     "referenced_widgets": [
      "875bbeb5b170432993a5a3b60bac4583",
      "851ae5e845c640b682584f1bac579b4a",
      "f47469c57de84001914ae78b5111448f",
      "95222ffa21b64a6aa669606a0ac04d67",
      "b5dd58424c624203ae3fc8c7b186dfd7",
      "ecd119687e754ef3b6396b0f3a6fa578",
      "ec7a297fe7fb42898f40efd96543718e",
      "ae49ea6fee404ed0b0b9b650788e02f1",
      "8d52bb5b83344238821e057345d9cec7",
      "050f3f30a9ce4ed5845035b45ae67696",
      "4af9e08c22604e19a9e5ad9a6ee9f72e",
      "bc537361dd3842b9a9ba73961fbc837d",
      "f15734687d8b4d319ad0e6a354ae52b4",
      "a1170b2bcaa94b3eace8dfae07abdfc1",
      "f9a04bddbf394386817b6a72c1f7cbf7",
      "cc12acff2f054f13a85fca341d2491d9",
      "f0c0cd81715442808d526fcd0c97dd86",
      "f9bfc962466340a5bdd201f7990cdcc7",
      "b501c5a4d0ef40a8855c150b908376d7",
      "c5048932dac8488ca040f750bf9bf86a",
      "dedb78c6049f409a837346b3253dd6af",
      "6955c33673f444e582a27d7a28dbf2c8",
      "1befcf969d8349b684dc4dd95c595576",
      "1c75aacfbb164a78a6137556153fb86e",
      "027af0bb531141f6bbc2e8031651a5d3",
      "5be9bfa273a64726be95a2aabe1c949c",
      "c99de6ed025d4fccb2405b4d430bc7a7",
      "497e444e289541e091b4a13692700ffb",
      "14d713bda1a74f0eb81fd3e5097cc84c",
      "878d8fc7f8b64154bd6a9b9fdf708cf4",
      "cc59cc34c18b49d1baa639d84a61c790",
      "90fff42a7b7748c786b5331323ad477f",
      "29437391d2d2464f876d90410dd0edda",
      "46fa15b1811d45788dc7e879fb5fd524",
      "f52276c414ef4590b92a75668b34247f",
      "85a0d963ef3344338472e677ac56dc7e",
      "d87bc8dc2a414e24b319c993eb893445",
      "e833e338ae354ea3be563d2d6fedaef2",
      "ad3baed8953644fbb1abb1f4b36107df",
      "9265977cadaf4b20a3329b2da7284399",
      "ba4a2cb8e5474f94b034277479fd1b12",
      "47d185d033ae415abecc8dc0d3aabed6",
      "c23803bdd0eb4815b3fe689e6bfcb1e3",
      "e44500507aa84ee1ac197bcc95c91839"
     ]
    },
    "id": "BHxvngYLCJN5",
    "outputId": "da0d6103-97ee-479d-9ce4-712789e036ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  cpu \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 in training: 100%|████████████████████| 469/469 [01:13<00:00,  6.37it/s]\n",
      "Training:  20%|███████                            | 1/5 [01:13<04:54, 73.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 loss: 2.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 in training: 100%|████████████████████| 469/469 [01:13<00:00,  6.34it/s]\n",
      "Training:  40%|██████████████                     | 2/5 [02:27<03:41, 73.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 loss: 1.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 in training: 100%|████████████████████| 469/469 [01:12<00:00,  6.48it/s]\n",
      "Training:  60%|█████████████████████              | 3/5 [03:39<02:26, 73.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 loss: 1.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 in training: 100%|████████████████████| 469/469 [01:12<00:00,  6.46it/s]\n",
      "Training:  80%|████████████████████████████       | 4/5 [04:52<01:12, 72.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 loss: 1.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 in training: 100%|████████████████████| 469/469 [01:12<00:00,  6.45it/s]\n",
      "Training: 100%|███████████████████████████████████| 5/5 [06:05<00:00, 73.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 loss: 1.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████████████████████████████| 79/79 [00:06<00:00, 11.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.73\n",
      "Test accuracy: 72.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "\n",
    "def patchify(images, n_patches):\n",
    "    n, c, h, w = images.shape\n",
    "\n",
    "    assert h == w, \"Patchify method is implemented for square images only\"\n",
    "\n",
    "    patches = torch.zeros(n, n_patches ** 2, h * w * c // n_patches ** 2)\n",
    "    patch_size = h // n_patches\n",
    "\n",
    "    for idx, image in enumerate(images):\n",
    "        for i in range(n_patches):\n",
    "            for j in range(n_patches):\n",
    "                patch = image[:, i * patch_size: (i + 1) * patch_size, j * patch_size: (j + 1) * patch_size]\n",
    "                patches[idx, i * n_patches + j] = patch.flatten()\n",
    "    return patches\n",
    "\n",
    "\n",
    "class MyMSA(nn.Module):\n",
    "    def __init__(self, d, n_heads=2):\n",
    "        super(MyMSA, self).__init__()\n",
    "        self.d = d\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "        assert d % n_heads == 0, f\"Can't divide dimension {d} into {n_heads} heads\"\n",
    "\n",
    "        d_head = int(d / n_heads)\n",
    "        self.q_mappings = nn.ModuleList([nn.Linear(d_head, d_head) for _ in range(self.n_heads)])\n",
    "        self.k_mappings = nn.ModuleList([nn.Linear(d_head, d_head) for _ in range(self.n_heads)])\n",
    "        self.v_mappings = nn.ModuleList([nn.Linear(d_head, d_head) for _ in range(self.n_heads)])\n",
    "        self.d_head = d_head\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, sequences):\n",
    "        # Sequences has shape (N, seq_length, token_dim)\n",
    "        # We go into shape    (N, seq_length, n_heads, token_dim / n_heads)\n",
    "        # And come back to    (N, seq_length, item_dim)  (through concatenation)\n",
    "        result = []\n",
    "        for sequence in sequences:\n",
    "            seq_result = []\n",
    "            for head in range(self.n_heads):\n",
    "                q_mapping = self.q_mappings[head]\n",
    "                k_mapping = self.k_mappings[head]\n",
    "                v_mapping = self.v_mappings[head]\n",
    "\n",
    "                seq = sequence[:, head * self.d_head: (head + 1) * self.d_head]\n",
    "                q, k, v = q_mapping(seq), k_mapping(seq), v_mapping(seq)\n",
    "\n",
    "                attention = self.softmax(q @ k.T / (self.d_head ** 0.5))\n",
    "                seq_result.append(attention @ v)\n",
    "            result.append(torch.hstack(seq_result))\n",
    "        return torch.cat([torch.unsqueeze(r, dim=0) for r in result])\n",
    "\n",
    "\n",
    "class MyViTBlock(nn.Module):\n",
    "    def __init__(self, hidden_d, n_heads, mlp_ratio=4):\n",
    "        super(MyViTBlock, self).__init__()\n",
    "        self.hidden_d = hidden_d\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(hidden_d)\n",
    "        self.mhsa = MyMSA(hidden_d, n_heads)\n",
    "        self.norm2 = nn.LayerNorm(hidden_d)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_d, mlp_ratio * hidden_d),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(mlp_ratio * hidden_d, hidden_d)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x + self.mhsa(self.norm1(x))\n",
    "        out = out + self.mlp(self.norm2(out))\n",
    "        return out\n",
    "\n",
    "\n",
    "class MyViT(nn.Module):\n",
    "    def __init__(self, chw, n_patches=7, n_blocks=2, hidden_d=8, n_heads=2, out_d=10):\n",
    "        # Super constructor\n",
    "        super(MyViT, self).__init__()\n",
    "        \n",
    "        # Attributes\n",
    "        self.chw = chw # ( C , H , W )\n",
    "        self.n_patches = n_patches\n",
    "        self.n_blocks = n_blocks\n",
    "        self.n_heads = n_heads\n",
    "        self.hidden_d = hidden_d\n",
    "        \n",
    "        # Input and patches sizes\n",
    "        assert chw[1] % n_patches == 0, \"Input shape not entirely divisible by number of patches\"\n",
    "        assert chw[2] % n_patches == 0, \"Input shape not entirely divisible by number of patches\"\n",
    "        self.patch_size = (chw[1] / n_patches, chw[2] / n_patches)\n",
    "\n",
    "        # 1) Linear mapper\n",
    "        self.input_d = int(chw[0] * self.patch_size[0] * self.patch_size[1])\n",
    "        self.linear_mapper = nn.Linear(self.input_d, self.hidden_d)\n",
    "        \n",
    "        # 2) Learnable classification token\n",
    "        self.class_token = nn.Parameter(torch.rand(1, self.hidden_d))\n",
    "        \n",
    "        # 3) Positional embedding\n",
    "        self.register_buffer('positional_embeddings', get_positional_embeddings(n_patches ** 2 + 1, hidden_d), persistent=False)\n",
    "        \n",
    "        # 4) Transformer encoder blocks\n",
    "        self.blocks = nn.ModuleList([MyViTBlock(hidden_d, n_heads) for _ in range(n_blocks)])\n",
    "        \n",
    "        # 5) Classification MLPk\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(self.hidden_d, out_d),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "\n",
    "    def forward(self, images):\n",
    "        # Dividing images into patches\n",
    "        n, c, h, w = images.shape\n",
    "        patches = patchify(images, self.n_patches).to(self.positional_embeddings.device)\n",
    "        \n",
    "        # Running linear layer tokenization\n",
    "        # Map the vector corresponding to each patch to the hidden size dimension\n",
    "        tokens = self.linear_mapper(patches)\n",
    "        \n",
    "        # Adding classification token to the tokens\n",
    "        tokens = torch.cat((self.class_token.expand(n, 1, -1), tokens), dim=1)\n",
    "        \n",
    "        # Adding positional embedding\n",
    "        out = tokens + self.positional_embeddings.repeat(n, 1, 1)\n",
    "        \n",
    "        # Transformer Blocks\n",
    "        for block in self.blocks:\n",
    "            out = block(out)\n",
    "            \n",
    "        # Getting the classification token only\n",
    "        out = out[:, 0]\n",
    "        \n",
    "        return self.mlp(out) # Map to output dimension, output category distribution\n",
    "    \n",
    "\n",
    "\n",
    "def get_positional_embeddings(sequence_length, d):\n",
    "    result = torch.ones(sequence_length, d)\n",
    "    for i in range(sequence_length):\n",
    "        for j in range(d):\n",
    "            result[i][j] = np.sin(i / (10000 ** (j / d))) if j % 2 == 0 else np.cos(i / (10000 ** ((j - 1) / d)))\n",
    "    return result\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Loading data\n",
    "    transform = ToTensor()\n",
    "\n",
    "    train_set = MNIST(root='./../datasets', train=True, download=True, transform=transform)\n",
    "    test_set = MNIST(root='./../datasets', train=False, download=True, transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(train_set, shuffle=True, batch_size=128)\n",
    "    test_loader = DataLoader(test_set, shuffle=False, batch_size=128)\n",
    "\n",
    "    # Defining model and training options\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device: \", device, f\"({torch.cuda.get_device_name(device)})\" if torch.cuda.is_available() else \"\")\n",
    "    model = MyViT((1, 28, 28), n_patches=7, n_blocks=2, hidden_d=8, n_heads=2, out_d=10).to(device)\n",
    "    N_EPOCHS = 5\n",
    "    LR = 0.005\n",
    "\n",
    "    # Training loop\n",
    "    optimizer = Adam(model.parameters(), lr=LR)\n",
    "    criterion = CrossEntropyLoss()\n",
    "    for epoch in trange(N_EPOCHS, desc=\"Training\"):\n",
    "        train_loss = 0.0\n",
    "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch + 1} in training\",position=0,leave=True):\n",
    "            x, y = batch\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_hat = model(x)\n",
    "            loss = criterion(y_hat, y)\n",
    "\n",
    "            train_loss += loss.detach().cpu().item() / len(train_loader)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{N_EPOCHS} loss: {train_loss:.2f}\")\n",
    "\n",
    "    # Test loop\n",
    "    with torch.no_grad():\n",
    "        correct, total = 0, 0\n",
    "        test_loss = 0.0\n",
    "        for batch in tqdm(test_loader, desc=\"Testing\"):\n",
    "            x, y = batch\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_hat = model(x)\n",
    "            loss = criterion(y_hat, y)\n",
    "            test_loss += loss.detach().cpu().item() / len(test_loader)\n",
    "\n",
    "            correct += torch.sum(torch.argmax(y_hat, dim=1) == y).detach().cpu().item()\n",
    "            total += len(x)\n",
    "        print(f\"Test loss: {test_loss:.2f}\")\n",
    "        print(f\"Test accuracy: {correct / total * 100:.2f}%\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extending a classical vision transformer to a quantum vision transformer would require incorporating quantum mechanics into the model's architecture. This would likely involve the use of quantum algorithms and quantum hardware, such as quantum circuits and qubits, to perform the computations.\n",
    "\n",
    "Here is a high-level sketch of what a quantum vision transformer architecture might look like:\n",
    "\n",
    "1) Quantum Image Encoding: The first step in the architecture would be to encode the classical image data into a quantum state. This could be done using quantum image encoding techniques, such as the quantum Fourier transform, to map the classical image pixels to quantum states.\n",
    "\n",
    "2) Quantum Attention Mechanisms: The next step would be to perform quantum attention mechanisms to process the quantum image encoding. This could be done using quantum circuits that perform quantum transformations, such as the quantum phase estimation algorithm, to compute attention scores for the different regions of the image.\n",
    "\n",
    "3) Quantum Layers: The quantum vision transformer would then consist of multiple quantum layers, each of which would perform quantum transformations on the quantum image encoding. These transformations could be based on quantum algorithms, such as the quantum alternating operator ansatz or the quantum circuit-centric approach, to process the quantum image encoding.\n",
    "\n",
    "4) Quantum Pooling: After the quantum layers have processed the quantum image encoding, a quantum pooling operation would be performed to aggregate the information from the different regions of the image. This could be done using quantum algorithms, such as the quantum maximum finding algorithm, to compute the maximum value for each region of the image.\n",
    "\n",
    "5) Quantum Classification: Finally, the quantum image encoding would be passed through a quantum classifier to make the final prediction. This could be done using quantum algorithms, such as the quantum support vector machine or quantum neural networks, to classify the image based on its quantum encoding.\n",
    "\n",
    "It's worth noting that this is just one possible approach to designing a quantum vision transformer architecture, and there are many other ways to incorporate quantum mechanics into the model's architecture. Additionally, quantum hardware and software technologies are still in their early stages of development, so there may be technical limitations to implementing a full-fledged quantum vision transformer at this time. However, as quantum technologies continue to advance, it may become possible to build more sophisticated quantum vision transformers in the future."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "JQi86HXFNL5k",
    "8OKUVpPt-ujk",
    "GgLU0cloky62",
    "Xa2YNDgdCHLU"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "027af0bb531141f6bbc2e8031651a5d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_878d8fc7f8b64154bd6a9b9fdf708cf4",
      "max": 1648877,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cc59cc34c18b49d1baa639d84a61c790",
      "value": 1648877
     }
    },
    "050f3f30a9ce4ed5845035b45ae67696": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "14d713bda1a74f0eb81fd3e5097cc84c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1befcf969d8349b684dc4dd95c595576": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1c75aacfbb164a78a6137556153fb86e",
       "IPY_MODEL_027af0bb531141f6bbc2e8031651a5d3",
       "IPY_MODEL_5be9bfa273a64726be95a2aabe1c949c"
      ],
      "layout": "IPY_MODEL_c99de6ed025d4fccb2405b4d430bc7a7"
     }
    },
    "1c75aacfbb164a78a6137556153fb86e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_497e444e289541e091b4a13692700ffb",
      "placeholder": "​",
      "style": "IPY_MODEL_14d713bda1a74f0eb81fd3e5097cc84c",
      "value": "100%"
     }
    },
    "29437391d2d2464f876d90410dd0edda": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "46fa15b1811d45788dc7e879fb5fd524": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f52276c414ef4590b92a75668b34247f",
       "IPY_MODEL_85a0d963ef3344338472e677ac56dc7e",
       "IPY_MODEL_d87bc8dc2a414e24b319c993eb893445"
      ],
      "layout": "IPY_MODEL_e833e338ae354ea3be563d2d6fedaef2"
     }
    },
    "47d185d033ae415abecc8dc0d3aabed6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "497e444e289541e091b4a13692700ffb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4af9e08c22604e19a9e5ad9a6ee9f72e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5be9bfa273a64726be95a2aabe1c949c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_90fff42a7b7748c786b5331323ad477f",
      "placeholder": "​",
      "style": "IPY_MODEL_29437391d2d2464f876d90410dd0edda",
      "value": " 1648877/1648877 [00:00&lt;00:00, 25667839.71it/s]"
     }
    },
    "6955c33673f444e582a27d7a28dbf2c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "851ae5e845c640b682584f1bac579b4a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ecd119687e754ef3b6396b0f3a6fa578",
      "placeholder": "​",
      "style": "IPY_MODEL_ec7a297fe7fb42898f40efd96543718e",
      "value": "100%"
     }
    },
    "85a0d963ef3344338472e677ac56dc7e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ba4a2cb8e5474f94b034277479fd1b12",
      "max": 4542,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_47d185d033ae415abecc8dc0d3aabed6",
      "value": 4542
     }
    },
    "875bbeb5b170432993a5a3b60bac4583": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_851ae5e845c640b682584f1bac579b4a",
       "IPY_MODEL_f47469c57de84001914ae78b5111448f",
       "IPY_MODEL_95222ffa21b64a6aa669606a0ac04d67"
      ],
      "layout": "IPY_MODEL_b5dd58424c624203ae3fc8c7b186dfd7"
     }
    },
    "878d8fc7f8b64154bd6a9b9fdf708cf4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8d52bb5b83344238821e057345d9cec7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "90fff42a7b7748c786b5331323ad477f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9265977cadaf4b20a3329b2da7284399": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "95222ffa21b64a6aa669606a0ac04d67": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_050f3f30a9ce4ed5845035b45ae67696",
      "placeholder": "​",
      "style": "IPY_MODEL_4af9e08c22604e19a9e5ad9a6ee9f72e",
      "value": " 9912422/9912422 [00:00&lt;00:00, 109967998.72it/s]"
     }
    },
    "a1170b2bcaa94b3eace8dfae07abdfc1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b501c5a4d0ef40a8855c150b908376d7",
      "max": 28881,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c5048932dac8488ca040f750bf9bf86a",
      "value": 28881
     }
    },
    "ad3baed8953644fbb1abb1f4b36107df": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ae49ea6fee404ed0b0b9b650788e02f1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b501c5a4d0ef40a8855c150b908376d7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b5dd58424c624203ae3fc8c7b186dfd7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ba4a2cb8e5474f94b034277479fd1b12": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bc537361dd3842b9a9ba73961fbc837d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f15734687d8b4d319ad0e6a354ae52b4",
       "IPY_MODEL_a1170b2bcaa94b3eace8dfae07abdfc1",
       "IPY_MODEL_f9a04bddbf394386817b6a72c1f7cbf7"
      ],
      "layout": "IPY_MODEL_cc12acff2f054f13a85fca341d2491d9"
     }
    },
    "c23803bdd0eb4815b3fe689e6bfcb1e3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5048932dac8488ca040f750bf9bf86a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c99de6ed025d4fccb2405b4d430bc7a7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cc12acff2f054f13a85fca341d2491d9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cc59cc34c18b49d1baa639d84a61c790": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d87bc8dc2a414e24b319c993eb893445": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c23803bdd0eb4815b3fe689e6bfcb1e3",
      "placeholder": "​",
      "style": "IPY_MODEL_e44500507aa84ee1ac197bcc95c91839",
      "value": " 4542/4542 [00:00&lt;00:00, 189610.33it/s]"
     }
    },
    "dedb78c6049f409a837346b3253dd6af": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e44500507aa84ee1ac197bcc95c91839": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e833e338ae354ea3be563d2d6fedaef2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ec7a297fe7fb42898f40efd96543718e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ecd119687e754ef3b6396b0f3a6fa578": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f0c0cd81715442808d526fcd0c97dd86": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f15734687d8b4d319ad0e6a354ae52b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f0c0cd81715442808d526fcd0c97dd86",
      "placeholder": "​",
      "style": "IPY_MODEL_f9bfc962466340a5bdd201f7990cdcc7",
      "value": "100%"
     }
    },
    "f47469c57de84001914ae78b5111448f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ae49ea6fee404ed0b0b9b650788e02f1",
      "max": 9912422,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8d52bb5b83344238821e057345d9cec7",
      "value": 9912422
     }
    },
    "f52276c414ef4590b92a75668b34247f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ad3baed8953644fbb1abb1f4b36107df",
      "placeholder": "​",
      "style": "IPY_MODEL_9265977cadaf4b20a3329b2da7284399",
      "value": "100%"
     }
    },
    "f9a04bddbf394386817b6a72c1f7cbf7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dedb78c6049f409a837346b3253dd6af",
      "placeholder": "​",
      "style": "IPY_MODEL_6955c33673f444e582a27d7a28dbf2c8",
      "value": " 28881/28881 [00:00&lt;00:00, 1435886.51it/s]"
     }
    },
    "f9bfc962466340a5bdd201f7990cdcc7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
